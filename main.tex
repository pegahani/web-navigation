%
% File naacl2019.tex
%
%% Based on the style files for ACL 2018 and NAACL 2018, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{naaclhlt2019}
\usepackage{times}
\usepackage{latexsym}

\usepackage{url}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}

%%%%%neww added commands by writer%%%%%%
\newcommand{\PA}[1]{{\textcolor{blue}{#1}}}
\newcommand{\question}[1]{{\textcolor{orange}{#1}}}

\renewcommand{\labelitemii}{$\diamond$}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage[]{algorithm2e}

%%%%%neww added commands by writer%%%%%%

\title{A Navigation Web Search System for Expert Tracking using Deep Reinforcement Learning Approach}

\author{Pegah Alizadeh \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\\And
  Josue Urbina \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain}
  Carl Posthuma \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} 
  Jorge Garcia \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} 
  Ivan Meza \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} 
  Luis Pineda \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain}
  \\}
\date{}

\begin{document}
\maketitle
\begin{abstract}
We present a modification of \textit{Unoporuno} system first introduced by Flores et al. \citep{Flores2012} as an application of deep reinforcement learning and natural language processing methods to the immigration sociology. A manually extracted database containing researcher and experts of central and south America is supported by the sociologists. By receiving a person name from the sociologists database, We propose a method for extracting her organisation names and related activate years over her professional years using deep reinforcement learning approach. We improve the unoporuno system by tracking each person's professional movements instead of just verifying the hers mobility w.r.t her origin place. 
\end{abstract}

\section{Introduction}
Luis Fernandez left his origin country (Argentina) in  $2005$ for doing a PHD in telecommunication. What does he do now? where is he now? where were other universities or organisations that he has worked for so far? for which periods? what are his specialties? In the other words what is his \textit{professional track}. Sociologists of immigration and particularly those who are interested in ``brain drain" domain requires great deal of time, manual internet search or data source search (such as CVs, personal Web Pages, etc.) to answer such fine-grained examples \cite{Auriol2010,Meyer2006}.

%%%%%%%%%%%
\begin{figure}[!t]
\centering
\includegraphics[scale=0.3]{./images/trajectory.png}
\caption{The graph in the top demonstrates Luis Fernandez's trajectory while the bottom one shows a local expert trajectory. }
\label{fig:traj}
\end{figure}
%%%%%%%%%

\PA{may be some state of the art should be added through the following explanation}\\
In this work, we are interested in extracting a trajectory for each given expert including her organisation names and the related years by searching their given names through the web and extracting as accurate as possible name entities (In the rest of this work, by the name entities we mean the organisation names, university names or dates) from the web.  For instance, a researcher as ``Luis Fernandez" has a mobile professional trajectory with various oraganisations and year of experience as figure~\ref{fig:traj} (top graph) though another person (the bottom graph) has a local professional trajectory and he works in his original country recently.  

An intuitive approach for tracking an expert professional trajectory contains two parts: querying various search engines with different keywords and extracting name entities from the list of snippets generated by each query. Here the main dilemma is that when is the proper moment for generating a new query and which snippets should be taken into account for extracting more accurate name entities w.r.t the expert professional trajectory. %According to figure~\ref{fig:navigate} 

In this paper, we propose a method for tracking each given expert's profession using deep reinforcement learning (DRL) approach. Deep Q-network usage in various problems and the tracking issue as a planning problem motivate us concentrating on this approach. Some recent problems have been solved by using Deep Q-network method such as information extraction \citep{narasimhan2016improving}, object detection in images \cite{Caicedo2015}, solving arithmetic word problems \cite{wang2018} and text generation \citep{Guo2015}. Inspiring Narasimhan et al. \shortcite{narasimhan2016improving} work on the information extraction problem for huge size search spaces and regarding tracking expert problem as a optimal policy search in RL, we consider deep Q-network and various neural network models to learn Q-value functions and approximate the optimal expert's track for a given expert name.  

Our main contributions in this paper are as the following:
\begin{itemize}
\item To the best of our knowledge, a people tracking system based on Deep RL methods is first presented in this paper.
\item The Q-value function depends on the sequence of selection snippets through the web. For this reason, we replace the neural network of Deep Q-network with a long Short Term Memory (LSTM) and \PA{improves the result by \%  }
\item \PA{We test our methods on .... dataset nad improve the results by .... }
\end{itemize}

%\begin{figure}[!t]
%\centering
%\includegraphics[scale=0.22]{./images/navigate.png}
%\caption{\PA{This figure motivates the usage of reinforcement learning in navigating web. But it has two problems: quality and confidential names. Even if I selected a common general Spanish name.}}
%\label{fig:navigate}
%\end{figure}



\section{Related Work}

In this section we review the literature of the used \textit{Deep Reinforcement Learning (DRL)} methods for extracting information and introduce a background on application of \textit{Natural Language Processing (NLP)} and DRL methods on sociology of migration application and Web People Search (WPS) tasks. 

\paragraph{Web People Search (\PA{or any similar title reviewing the literature for navigating immigration data base in the web})}

\paragraph{Deep Reinforcement Learning}
\input{reinforcement.tex}

\section{Framework and Solution}
\input{framework.tex}

\section{Data}
\input{data.tex}

\section{Experiments}

\section{Conclusions}

\section*{Acknowledgments}

\bibliography{naaclhlt2019}
\bibliographystyle{acl_natbib}

\appendix

\section{Appendices}
\label{sec:appendix}


\section{Supplemental Material}
\label{sec:supplemental}

\end{document}
