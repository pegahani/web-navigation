%
% File naacl2019.tex
%
%% Based on the style files for ACL 2018 and NAACL 2018, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{naaclhlt2019}
\usepackage{times}
\usepackage{latexsym}

\usepackage{url}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}

%%%%%neww added commands by writer%%%%%%
\newcommand{\PA}[1]{{\textcolor{blue}{#1}}}
\newcommand{\question}[1]{{\textcolor{orange}{#1}}}

\definecolor{rouge}{rgb}{1,0,0}
\newcommand{\remJGF}[1]{{\color{rouge}{\emph{JGF : #1}}}}

\renewcommand{\labelitemii}{$\diamond$}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage[ruled,linesnumbered]{algorithm2e}

%%%%%neww added commands by writer%%%%%%

%\title{A Navigation Web Search System for  Expert Tracking \\ Using Deep Reinforcement Learning}
\title{Deep Reinforcement Learning for Expert Mobility Tracking from Web Search Results}

\author{Pegah Alizadeh \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\\And
  Josue Urbina \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain}
  Carl Posthuma \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} 
  Jorge Garcia Flores \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} 
  Ivan Meza \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} 
  Luis Pineda \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain}
  \\}
\date{}

\begin{document}
\maketitle
\begin{abstract}

  This paper presents an original approach for extracting experts mobility traces from the web based on deep reinforcement learning. In the broad context of Digital Humanities, the goal of our work is to assist migration sociologists studying expert's international mobility trajectories with natural language processing methods. Deep-Q networks have recently shown promising results improving information extraction methods from web results. Given an expert's name, our method harvests information from web search engines and extracts the optimal expert's mobility trajectory (a set of triplets containing institution, city and year) from it by means of a Deep-Q network and various neural network architectures for the Q-value function approximation. This paper presents experimental evidence improving the current state of the art on expert finding, and extending the existing task with a chronological graph of the experts professional trajectory. 

  %We present at a first time, a people tracking system (specifically the expert people with available and extractable information in the web) as an application of deep reinforcement learning and natural language processing methods to the immigration sociology. The Deep Q-network has been used for extracting information from huge size text datasets and finding the most precise name entities. In this paper, for the sociology term of usage, we propose a method for tracking a give person name and extracting her optimal professional trajectory by exploring the web and generating as less as possible number of queries. Our proposed approach is based on a Deep Q-network method with various neural networks for the Q-value function approximation. We improve the existed people search systems by tracking the experts professional trajectories instead of just labeling them as a mobile or local person w.r.t their origin countries.  
\end{abstract}

\section{Introduction}
Luis Fernandez grew up in Argentina and studied a Biotechnology Masters's degree at the University of Buenos Aires. In $2010$ he got an international scholarship and went to Essex University for a PhD. Where is he now? Did he stay in the UK, or did he come back to Argentina? How did his expert skills evolve? In other words, what are his \textit{professional mobility traces}?

Reaching expatriate members of the \textit{highly qualified diaspora} is a major challenge for policy makers \cite{CIDESAL}. Migrations sociologists studying mobility patterns of this \textit{diaspora of knowledge} use statistical sources, like population censues, labor force surveys and administrative data \cite{Turner}. However, these sources are not entirely satisfactory when monitoring constantly changing mobility trends, so recent scientific efforts have been dedicated to mine the Web in order better understand the dynamics of this expert migration flow \cite{GarciaFlores, Russians, Auriol2010}.

\remJGF{while this task differs from web people search}

%%%%%%%%%%%
\begin{figure}[!t]
\centering
\includegraphics[scale=0.3]{./images/trajectory.png}
\caption{Examples of professional mobility trajectories.}
\label{fig:traj}
\end{figure}
%%%%%%%%%
In this work, we are interested in extracting a trajectory for each given expert including her organisation names and the related years by searching their given names through the web and extracting as accurate as possible name entities (In the rest of this work, by the name entities we mean the organisation names, university names or dates) from the web.  For instance, a researcher as ``Luis Fernandez" has a mobile professional trajectory with various oraganisations and year of experience as figure~\ref{fig:traj} (top graph) though another person (the bottom graph) has a local professional trajectory and he works in his original country recently.  
  
An intuitive approach for tracking an expert professional trajectory contains two parts: querying various search engines with different keywords and extracting name entities from the list of snippets generated by each query. Here the main dilemma is that when is the proper moment for generating a new query and which snippets should be taken into account for extracting more accurate name entities w.r.t the expert professional trajectory. %According to figure~\ref{fig:navigate} 

In this paper, we propose a method for tracking each given expert's profession using deep reinforcement learning (DRL) approach. Deep Q-network (DQN) usage in various problems and the tracking issue as a planning problem motivate us concentrating on this approach. Some recent problems have been solved by using Deep Q-network method such as information extraction \citep{narasimhan2016improving}, object detection in images \cite{Caicedo2015}, solving arithmetic word problems \cite{wang2018} and text generation \citep{Guo2015}. Inspiring Narasimhan et al. \shortcite{narasimhan2016improving} work on the information extraction problem for huge size search spaces and regarding tracking expert problem as a optimal policy search in RL, we consider deep Q-network and various neural network models to learn Q-value functions and approximate the optimal expert's track for a given expert name.  

Our main contributions in this paper are as the following:
\begin{itemize}
\item To the best of our knowledge, a people tracking system based on Deep RL methods is first presented in this paper.
\item The Q-value function depends on the sequence of snippets selection through the web. For this reason, we replace the neural network of Deep Q-network \cite{mnih2015} with a long Short Term Memory (LSTM) network and \PA{improves the result by \%  }
\item \PA{We test our methods on .... dataset and improve the results by .... }
\end{itemize}

%\begin{figure}[!t]
%\centering
%\includegraphics[scale=0.22]{./images/navigate.png}
%\caption{\PA{This figure motivates the usage of reinforcement learning in navigating web. But it has two problems: quality and confidential names. Even if I selected a common general Spanish name.}}
%\label{fig:navigate}
%\end{figure}

\section{Related Work}
\remJGF{Complete the Digital Humanities part}
In this section we review the literature of the \textit{Deep Reinforcement Learning (DRL)} methods used for the web based information extraction problems. We also introduce a background on the application of \textit{Natural Language Processing (NLP)} and DRL methods on sociology of migration application and Web People Search (WPS) tasks. 

\paragraph{Web People Search (\PA{or any similar title reviewing the literature for navigating immigration data base in the web})}

\paragraph{Deep Reinforcement Learning}
\input{reinforcement.tex}

\section{Framework and Solution}
\input{framework.tex}

\section{Data}
\input{data.tex}

\section{Experiments}

\section{Conclusions}

\section*{Acknowledgments}

\bibliography{naaclhlt2019}
\bibliographystyle{acl_natbib}

\appendix

\section{Appendices}
\label{sec:appendix}


\section{Supplemental Material}
\label{sec:supplemental}

\end{document}
